{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import shlex\n",
    "import re\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, Markdown\n",
    "from tempfile import TemporaryDirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 400\n",
    "\n",
    "def show():\n",
    "    plt.savefig(f\"{show.fig_counter}.pdf\", dpi='figure', transparent=True, bbox_inches='tight')\n",
    "    show.fig_counter += 1\n",
    "    show.plt_show()\n",
    "\n",
    "show.fig_counter = 0\n",
    "show.plt_show = plt.show\n",
    "\n",
    "plt.show = show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EVENT_PATTERN = re.compile(r\"Event Summary:\\n - Total #individuals:\\n   \\d+\\n - Total #events:\\n   - raw:\\n     (\\d+)\\n   - deduplicated:\\n     (\\d+)\")\n",
    "EXECUTION_PATTERN = re.compile(r\"The simulation took:\\n - initialisation: ([^\\n]+)\\n - execution: ([^\\n]+)\\n - cleanup: ([^\\n]+)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TIME_PATTERN = re.compile(r\"(\\d+(?:\\.\\d+)?)([^\\d]+)\")\n",
    "TIME_UNITS = {\n",
    "    \"ns\": 0.000000001,\n",
    "    \"Âµs\": 0.000001,\n",
    "    \"ms\": 0.001,\n",
    "    \"s\": 1.0,\n",
    "}\n",
    "\n",
    "def parse_time(time_str):\n",
    "    match = TIME_PATTERN.match(time_str)\n",
    "    \n",
    "    if match is None:\n",
    "        return None\n",
    "    \n",
    "    return float(match.group(1)) * TIME_UNITS[match.group(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_directory = json.loads(subprocess.run(\"cargo metadata --format-version 1\".split(), capture_output=True).stdout)[\"target_directory\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate_throughput_monolithic(algorithm, speciation=0.001, seed=42, sample=1.0, scenario=\"NonSpatial(area:(100,100),deme:100)\"):\n",
    "    config = \"\".join(f\"\"\"\n",
    "    (\n",
    "        speciation: {speciation},\n",
    "        sample: {sample},\n",
    "        seed: {seed},\n",
    "\n",
    "        algorithm: {algorithm},\n",
    "\n",
    "        log: None,\n",
    "\n",
    "        scenario: {scenario},\n",
    "\n",
    "        reporters: [\n",
    "            Plugin(\n",
    "                library: \"{target_directory}/release/deps/libnecsim_plugins_common.so\",\n",
    "                reporters: [Counter(), Execution()]\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "    \"\"\".split()).replace(\",)\", \")\").replace(\",]\", \"]\")\n",
    "\n",
    "    # Run the simulation\n",
    "    result = subprocess.run(shlex.split(\n",
    "        \"cargo run --release --features rustcoalescence-algorithms-monolithic,\"\n",
    "        + \"rustcoalescence-algorithms-independent,rustcoalescence-algorithms-cuda\"\n",
    "        + f\" --quiet -- simulate '{config}'\"\n",
    "    ), check=True, capture_output=True, text=True)\n",
    "\n",
    "    match = EVENT_PATTERN.search(result.stdout)\n",
    "    if match is None:\n",
    "        print(result.stdout)\n",
    "        print(result.stderr)\n",
    "    raw_events = int(match.group(1))\n",
    "    deduplicated_events = int(match.group(2))\n",
    "    \n",
    "    match = EXECUTION_PATTERN.search(result.stdout)\n",
    "    if match is None:\n",
    "        print(result.stdout)\n",
    "        print(result.stderr)\n",
    "    initialisation = parse_time(match.group(1))\n",
    "    execution = parse_time(match.group(2))\n",
    "    cleanup = parse_time(match.group(3))\n",
    "        \n",
    "    return raw_events, deduplicated_events, initialisation, execution, cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def batch_simulation_many_seeds(simulate, seeds, args=tuple(), kwargs=dict(), silent=False, processes=mp.cpu_count()):\n",
    "    results = []\n",
    "\n",
    "    with tqdm(total=len(seeds), disable=silent) as progress:\n",
    "        def update_progress(result):\n",
    "            results.append(result)\n",
    "\n",
    "            progress.update()\n",
    "        \n",
    "        def update_error(err):\n",
    "            print(err)\n",
    "\n",
    "        with mp.Pool(processes) as pool:\n",
    "            for seed in seeds:\n",
    "                pool.apply_async(simulate, args, {**kwargs, \"seed\": seed}, update_progress, update_error)\n",
    "\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# RAM Information:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       ">```\n",
       "              total        used        free      shared  buff/cache   available\n",
       ">Mem:       16319132      821644    11467528      271064     4029960    14889368\n",
       ">Swap:       4194300           0     4194300\n",
       ">```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# CPU Information:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       ">```\n",
       "Architecture:                    x86_64\n",
       ">CPU op-mode(s):                  32-bit, 64-bit\n",
       ">Byte Order:                      Little Endian\n",
       ">Address sizes:                   46 bits physical, 48 bits virtual\n",
       ">CPU(s):                          8\n",
       ">On-line CPU(s) list:             0-7\n",
       ">Thread(s) per core:              2\n",
       ">Core(s) per socket:              4\n",
       ">Socket(s):                       1\n",
       ">NUMA node(s):                    1\n",
       ">Vendor ID:                       GenuineIntel\n",
       ">CPU family:                      6\n",
       ">Model:                           62\n",
       ">Model name:                      Intel(R) Xeon(R) CPU E5-1620 v2 @ 3.70GHz\n",
       ">Stepping:                        4\n",
       ">CPU MHz:                         2544.426\n",
       ">CPU max MHz:                     3900.0000\n",
       ">CPU min MHz:                     1200.0000\n",
       ">BogoMIPS:                        7382.37\n",
       ">Virtualisation:                  VT-x\n",
       ">L1d cache:                       128 KiB\n",
       ">L1i cache:                       128 KiB\n",
       ">L2 cache:                        1 MiB\n",
       ">L3 cache:                        10 MiB\n",
       ">NUMA node0 CPU(s):               0-7\n",
       ">Vulnerability Itlb multihit:     KVM: Mitigation: VMX disabled\n",
       ">Vulnerability L1tf:              Mitigation; PTE Inversion; VMX conditional cache flushes, SMT vulnerable\n",
       ">Vulnerability Mds:               Mitigation; Clear CPU buffers; SMT vulnerable\n",
       ">Vulnerability Meltdown:          Mitigation; PTI\n",
       ">Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp\n",
       ">Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization\n",
       ">Vulnerability Spectre v2:        Mitigation; Full generic retpoline, IBPB conditional, IBRS_FW, STIBP conditional, RSB filling\n",
       ">Vulnerability Srbds:             Not affected\n",
       ">Vulnerability Tsx async abort:   Not affected\n",
       ">Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm cpuid_fault epb pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase smep erms xsaveopt dtherm ida arat pln pts md_clear flush_l1d\n",
       ">```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# GPU Information:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       ">```\n",
       "Thu May 27 12:52:40 2021       \n",
       ">+-----------------------------------------------------------------------------+\n",
       ">| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\n",
       ">|-------------------------------+----------------------+----------------------+\n",
       ">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
       ">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
       ">|                               |                      |               MIG M. |\n",
       ">|===============================+======================+======================|\n",
       ">|   0  GeForce GTX 1080    Off  | 00000000:05:00.0  On |                  N/A |\n",
       ">| 28%   34C    P8     7W / 180W |     84MiB /  8119MiB |      0%      Default |\n",
       ">|                               |                      |                  N/A |\n",
       ">+-------------------------------+----------------------+----------------------+\n",
       ">                                                                               \n",
       ">+-----------------------------------------------------------------------------+\n",
       ">| Processes:                                                                  |\n",
       ">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
       ">|        ID   ID                                                   Usage      |\n",
       ">|=============================================================================|\n",
       ">|    0   N/A  N/A      4336      G   /usr/lib/xorg/Xorg                 79MiB |\n",
       ">+-----------------------------------------------------------------------------+\n",
       ">```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"# RAM Information:\"))\n",
    "\n",
    "display(Markdown('>```\\n' + subprocess.run(\n",
    "    shlex.split(\"free\"), check=True, capture_output=True, text=True\n",
    ").stdout.replace('\\n', '\\n>') + '```'))\n",
    "\n",
    "display(Markdown(\"# CPU Information:\"))\n",
    "\n",
    "display(Markdown('>```\\n' + subprocess.run(\n",
    "    shlex.split(\"lscpu\"), check=True, capture_output=True, text=True\n",
    ").stdout.replace('\\n', '\\n>') + '```'))\n",
    "\n",
    "display(Markdown(\"# GPU Information:\"))\n",
    "\n",
    "display(Markdown('>```\\n' + subprocess.run(\n",
    "    shlex.split(\"nvidia-smi\"), check=True, capture_output=True, text=True\n",
    ").stdout.replace('\\n', '\\n>') + '```'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Event throughput:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Classical:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 160/160 [02:11<00:00,  1.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### NonSpatial: 1577368.8/s Â± 51740.9/s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 160/160 [02:16<00:00,  1.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### AlmostInfinite: 1551667.5/s Â± 12296.2/s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 160/160 [02:16<00:00,  1.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### SpatiallyExplicit: 1551821.9/s Â± 10487.2/s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Gillespie:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 160/160 [05:02<00:00,  1.89s/it]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### NonSpatial: 538211.1/s Â± 14971.3/s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 160/160 [04:53<00:00,  1.84s/it]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### AlmostInfinite: 549094.4/s Â± 16336.1/s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 160/160 [05:04<00:00,  1.90s/it]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### SpatiallyExplicit: 537213.9/s Â± 4565.7/s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## SkippingGillespie:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 160/160 [05:08<00:00,  1.93s/it]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### NonSpatial: 526081.1/s Â± 6298.6/s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 160/160 [05:07<00:00,  1.92s/it]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### AlmostInfinite: 526793.3/s Â± 6764.2/s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 160/160 [05:09<00:00,  1.93s/it]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### SpatiallyExplicit: 526430.0/s Â± 5825.3/s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Independent:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 160/160 [03:11<00:00,  1.20s/it]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### NonSpatial: 784124.3/s Â± 63081.6/s [raw: 1388804.5/s Â± 112076.3/s]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 160/160 [03:12<00:00,  1.20s/it]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### AlmostInfinite: 768352.9/s Â± 32482.2/s [raw: 1360074.7/s Â± 57345.2/s]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 160/160 [03:14<00:00,  1.21s/it]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### SpatiallyExplicit: 760516.8/s Â± 29374.0/s [raw: 1346595.9/s Â± 51733.8/s]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## CUDA:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 160/160 [43:53<00:00, 16.46s/it]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### NonSpatial: 424552.1/s Â± 4465.9/s [raw: 889057.5/s Â± 9456.9/s]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 160/160 [43:52<00:00, 16.45s/it]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### AlmostInfinite: 424325.0/s Â± 4985.9/s [raw: 888711.5/s Â± 10317.8/s]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 160/160 [43:46<00:00, 16.42s/it]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### SpatiallyExplicit: 425735.7/s Â± 5438.0/s [raw: 891539.7/s Â± 10969.9/s]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"# Event throughput:\"))\n",
    "\n",
    "for algorithm in [\n",
    "    \"Classical()\", \"Gillespie()\", \"SkippingGillespie()\",\n",
    "    f\"\"\"Independent(\n",
    "        dedup_cache: Relative(factor: {1.0}),\n",
    "        delta_t: {2.0},\n",
    "        parallelism_mode: Monolithic(event_slice: {100*100*100})\n",
    "    )\"\"\",\n",
    "    f\"\"\"CUDA(\n",
    "        ptx_jit: true,\n",
    "        dedup_cache: Relative(factor: {1.0}),\n",
    "        delta_t: {2.0},\n",
    "        parallelism_mode: Monolithic(event_slice: {100*100*100})\n",
    "    )\"\"\"\n",
    "]:\n",
    "    display(Markdown(f\"## {algorithm[:algorithm.find('(')]}:\"))\n",
    "    \n",
    "    for scenario, sample in [\n",
    "        (f\"NonSpatial(area: ({100}, {100}), deme: {100})\", 1.0),\n",
    "        (f\"AlmostInfinite(radius: {564}, sigma: {10.0})\", 1.0),\n",
    "        (f\"\"\"SpatiallyExplicit(\n",
    "            habitat: \"{target_directory}/../maps/madingley/fg0size12/habitat.tif\",\n",
    "            dispersal: \"{target_directory}/../maps/madingley/fg0size12/dispersal.tif\"\n",
    "        )\"\"\", 0.000025),\n",
    "    ]:\n",
    "        seeds = np.random.randint(0, np.iinfo(\"uint64\").max, dtype=\"uint64\", size=160)\n",
    "\n",
    "        raw_events, deduplicated_events, initialisations, executions, cleanups = zip(*batch_simulation_many_seeds(\n",
    "            simulate_throughput_monolithic, seeds, args=(algorithm,), kwargs={\n",
    "                \"scenario\":\"NonSpatial(area:(100,100),deme:100)\", \"speciation\":0.001\n",
    "            }, silent=False, processes=(1 if algorithm.startswith(\"CUDA\") else mp.cpu_count()),\n",
    "        ))\n",
    "        \n",
    "        raw_events = np.array(raw_events)\n",
    "        deduplicated_events = np.array(deduplicated_events)\n",
    "        executions = np.array(executions)\n",
    "        \n",
    "        raw_throughput = np.round(np.mean(raw_events / executions), 1)\n",
    "        raw_std = np.round(np.std(raw_events / executions), 1)\n",
    "        \n",
    "        throughput = np.round(np.mean(deduplicated_events / executions), 1)\n",
    "        std = np.round(np.std(deduplicated_events / executions), 1)\n",
    "        \n",
    "        if raw_throughput != throughput:\n",
    "            display(Markdown(f\"### {scenario[:scenario.find('(')]}: {throughput}/s Â± {std}/s [raw: {raw_throughput}/s Â± {raw_std}/s]\"))\n",
    "        else:\n",
    "            display(Markdown(f\"### {scenario[:scenario.find('(')]}: {throughput}/s Â± {std}/s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
